import 'dart:convert';
import 'dart:typed_data';
import 'package:flutter/foundation.dart';
import 'package:flutter_dotenv/flutter_dotenv.dart';
import 'package:lidarmesure/models/user.dart';
import 'package:lidarmesure/models/session.dart';
import 'package:http/http.dart' as http;
import 'package:image/image.dart' as img;

/// Professional Podology AI Assistant Service
/// Uses Groq API (FREE) for foot scan analysis with LLaMA models
class PodologyAIService {
  static String get _apiKey => dotenv.env['GROQ_API_KEY'] ?? '';
  // Mod√®le texte pour les conversations
  static const String _textModel = 'llama-3.3-70b-versatile';
  // Mod√®le vision pour l'analyse d'images (Llama 4 Scout - nouveau mod√®le Groq)
  static const String _visionModel = 'meta-llama/llama-4-scout-17b-16e-instruct';
  static const String _apiUrl = 'https://api.groq.com/openai/v1/chat/completions';

  static const String _systemPrompt = '''
Vous √™tes **SOLOL AI**, l'assistant intelligent int√©gr√© √† l'application SOLOL de podologie num√©rique.

## üéØ VOTRE MISSION
Accompagner les professionnels de sant√© dans l'analyse des scans de pieds r√©alis√©s avec l'app SOLOL qui utilise la segmentation SAM (Segment Anything Model) pour mesurer pr√©cis√©ment les pieds.

## üì± CONTEXTE DE L'APPLICATION
- L'utilisateur a pris des photos du pied (vue dessus + vue profil)
- Le syst√®me SAM a segment√© le pied et calcul√© les m√©triques
- Vous avez acc√®s aux donn√©es patient et aux mesures du scan

## üî¨ EXPERTISE CLINIQUE

### Pathologies √† identifier
- **Hallux Valgus**: D√©viation gros orteil > 15¬∞
- **Pronation/Supination**: Analyse de l'appui
- **Pieds plats/creux**: √âvaluation de la vo√ªte
- **M√©tatarsalgies**: Douleurs avant-pied

### Analyse des mesures
- Correspondance longueur/pointure d√©clar√©e
- √âvaluation largeur avant-pied
- Fiabilit√© de la mesure (confidence)

### Recommandations semelles
- **Confort**: Pieds normaux
- **Soutien**: Pronation l√©g√®re
- **Correctrices**: Pathologies marqu√©es
- **Sport**: Activit√© physique
- **Diab√©tiques**: Protection zones √† risque

## üí¨ STYLE DE R√âPONSE
- **Concis et structur√©** - R√©ponses claires, pas de pav√©s
- **Emojis mod√©r√©s** - Pour la lisibilit√© (üìä üîç ‚ö†Ô∏è üí° üëü)
- **Professionnel** - Terminologie m√©dicale appropri√©e
- **Actionnable** - Recommandations pratiques

## ‚ö†Ô∏è R√àGLES IMPORTANTES
1. Ne jamais inventer de donn√©es - utiliser uniquement ce qui est fourni
2. Signaler si les mesures semblent incoh√©rentes
3. Toujours contextualiser par rapport au profil patient
4. R√©ponses en fran√ßais par d√©faut
''';

  final List<Map<String, dynamic>> _history = [];

  PodologyAIService();

  /// Initialize chat with patient and session context
  void initializeContext({
    required Patient patient,
    required Session session,
  }) {
    _history.clear();
    
    final contextMessage = _buildContextMessage(patient, session);
    _history.add({'role': 'user', 'content': contextMessage});
    _history.add({'role': 'assistant', 'content': _buildInitialResponse(patient, session)});
  }

  String _buildContextMessage(Patient patient, Session session) {
    final metrics = session.footMetrics;
    final buffer = StringBuffer();
    
    buffer.writeln('=== NOUVEAU DOSSIER PATIENT ===');
    buffer.writeln();
    buffer.writeln('üìã PROFIL PATIENT:');
    buffer.writeln('‚Ä¢ Nom: ${patient.fullName}');
    buffer.writeln('‚Ä¢ √Çge: ${patient.age} ans');
    buffer.writeln('‚Ä¢ Sexe: ${patient.sexeLabel()}');
    buffer.writeln('‚Ä¢ Pointure: ${patient.pointure}');
    buffer.writeln('‚Ä¢ Taille: ${patient.taille} cm');
    buffer.writeln('‚Ä¢ Poids: ${patient.poids} kg');
    buffer.writeln('‚Ä¢ IMC: ${(patient.poids / ((patient.taille / 100) * (patient.taille / 100))).toStringAsFixed(1)}');
    buffer.writeln();
    
    if (metrics.isNotEmpty) {
      buffer.writeln('üìè M√âTRIQUES DU SCAN:');
      for (final m in metrics) {
        buffer.writeln('‚Ä¢ ${m.sideLabel}:');
        buffer.writeln('  - Longueur: ${m.formattedLongueur}');
        buffer.writeln('  - Largeur: ${m.formattedLargeur}');
        buffer.writeln('  - Confiance: ${m.confidencePercentage}');
      }
      buffer.writeln();
    }
    
    buffer.writeln('üìÖ Session du: ${session.formattedDate}');
    buffer.writeln('Statut: ${session.statusLabel}');
    
    return buffer.toString();
  }

  String _buildInitialResponse(Patient patient, Session session) {
    final metrics = session.footMetrics;
    final buffer = StringBuffer();
    
    buffer.writeln('Bonjour, j\'ai bien re√ßu le dossier de **${patient.fullName}**.');
    buffer.writeln();
    
    if (metrics.isNotEmpty) {
      buffer.writeln('üìä **R√©sum√© des mesures:**');
      for (final m in metrics) {
        buffer.writeln('- ${m.sideLabel}: ${m.formattedLongueur} √ó ${m.formattedLargeur}');
      }
      buffer.writeln();
      buffer.writeln('Je suis pr√™t √† analyser les images du scan ou √† r√©pondre √† vos questions cliniques.');
      buffer.writeln();
      buffer.writeln('üí° *Vous pouvez me demander:*');
      buffer.writeln('- Une analyse d√©taill√©e des images');
      buffer.writeln('- Des recommandations de semelles');
      buffer.writeln('- L\'identification d\'anomalies potentielles');
      buffer.writeln('- La correspondance pointure/mesures');
    } else {
      buffer.writeln('Aucune mesure n\'est encore disponible pour ce patient.');
      buffer.writeln('Veuillez effectuer un scan pour obtenir une analyse compl√®te.');
    }
    
    return buffer.toString();
  }

  /// Analyze foot scan image with context
  Future<String> analyzeImage({
    required Uint8List imageBytes,
    required String mimeType,
    required Patient patient,
    required Session session,
    String? additionalPrompt,
  }) async {
    try {
      final prompt = additionalPrompt ?? 
        'Analysez cette image de scan podologique. Identifiez les anomalies visibles, '
        '√©valuez la qualit√© de la segmentation, et fournissez vos observations cliniques.';

      // Compresser l'image pour Groq (max ~4MB en base64, donc ~3MB en bytes)
      Uint8List processedBytes = await _compressImage(imageBytes, mimeType);
      debugPrint('üì¶ Image apr√®s compression: ${processedBytes.length} bytes');
      
      final base64Image = base64Encode(processedBytes);
      const mediaType = 'image/jpeg'; // Toujours JPEG apr√®s compression

      // Format OpenAI/Groq pour les images (image_url avec data URI)
      final imageContent = {
        'role': 'user',
        'content': [
          {
            'type': 'image_url',
            'image_url': {
              'url': 'data:$mediaType;base64,$base64Image',
            }
          },
          {'type': 'text', 'text': prompt}
        ]
      };
      _history.add(imageContent);

      // Utiliser le mod√®le vision pour l'analyse d'images
      final reply = await _sendToGroqAPI(useVision: true);
      _history.add({'role': 'assistant', 'content': reply});

      return reply;
    } catch (e, st) {
      debugPrint('PodologyAI analyzeImage error: $e\n$st');
      return 'Erreur lors de l\'analyse de l\'image: $e';
    }
  }

  /// Analyze image from URL
  Future<String> analyzeImageFromUrl({
    required String imageUrl,
    required Patient patient,
    required Session session,
    String? additionalPrompt,
  }) async {
    try {
      final response = await http.get(Uri.parse(imageUrl));
      if (response.statusCode != 200) {
        return 'Impossible de charger l\'image depuis le serveur.';
      }

      final mimeType = response.headers['content-type'] ?? 'image/png';
      return analyzeImage(
        imageBytes: response.bodyBytes,
        mimeType: mimeType,
        patient: patient,
        session: session,
        additionalPrompt: additionalPrompt,
      );
    } catch (e) {
      debugPrint('PodologyAI analyzeImageFromUrl error: $e');
      return 'Erreur lors du chargement de l\'image: $e';
    }
  }

  /// Send a text message to the AI
  Future<String> sendMessage(String message) async {
    try {
      _history.add({'role': 'user', 'content': message});
      final reply = await _sendToGroqAPI();
      _history.add({'role': 'assistant', 'content': reply});
      return reply;
    } catch (e, st) {
      debugPrint('PodologyAI sendMessage error: $e\n$st');
      return 'Erreur de communication avec l\'assistant: $e';
    }
  }

  /// Stream response for better UX
  Stream<String> streamMessage(String message) async* {
    try {
      _history.add({'role': 'user', 'content': message});
      final reply = await _sendToGroqAPI();
      _history.add({'role': 'assistant', 'content': reply});
      yield reply;
    } catch (e, st) {
      debugPrint('PodologyAI streamMessage error: $e\n$st');
      yield 'Erreur: $e';
    }
  }

  /// Send request to Groq API (OpenAI-compatible format)
  /// [useVision] - Use vision model for image analysis
  Future<String> _sendToGroqAPI({bool useVision = false}) async {
    // Pour le mod√®le texte, convertir les messages image en texte
    final processedHistory = _history.map((msg) {
      final content = msg['content'];
      if (!useVision && content is List) {
        // Extraire le texte des messages multimodaux pour le mod√®le texte
        final textParts = (content as List)
            .where((part) => part is Map && part['type'] == 'text')
            .map((part) => part['text'] as String)
            .join('\n');
        return {
          'role': msg['role'],
          'content': textParts.isNotEmpty 
              ? '[Image analys√©e] $textParts' 
              : '[Image analys√©e pr√©c√©demment]',
        };
      }
      return msg;
    }).toList();

    // Build messages with system prompt
    final messages = [
      {'role': 'system', 'content': _systemPrompt},
      ...processedHistory,
    ];

    final modelToUse = useVision ? _visionModel : _textModel;
    debugPrint('ü§ñ Using model: $modelToUse');

    final response = await http.post(
      Uri.parse(_apiUrl),
      headers: {
        'Content-Type': 'application/json',
        'Authorization': 'Bearer $_apiKey',
      },
      body: jsonEncode({
        'model': modelToUse,
        'max_tokens': 2048,
        'messages': messages,
      }),
    );

    if (response.statusCode == 200) {
      final data = jsonDecode(response.body);
      final choices = data['choices'] as List;
      if (choices.isNotEmpty) {
        return choices[0]['message']['content'] as String;
      }
      return 'Pas de r√©ponse.';
    } else {
      final error = jsonDecode(response.body);
      throw Exception(error['error']?['message'] ?? 'API Error: ${response.statusCode}');
    }
  }

  /// Compress image to reduce size for API
  /// Max size ~500KB for reliable Groq API calls
  Future<Uint8List> _compressImage(Uint8List imageBytes, String mimeType) async {
    try {
      // Decode the image
      img.Image? image = img.decodeImage(imageBytes);
      if (image == null) {
        debugPrint('‚ö†Ô∏è Impossible de d√©coder l\'image, envoi original');
        return imageBytes;
      }

      debugPrint('üìê Image originale: ${image.width}x${image.height}, ${imageBytes.length} bytes');

      // Resize if too large (max 1024px on longest side)
      const maxSize = 1024;
      if (image.width > maxSize || image.height > maxSize) {
        if (image.width > image.height) {
          image = img.copyResize(image, width: maxSize);
        } else {
          image = img.copyResize(image, height: maxSize);
        }
        debugPrint('üìê Image redimensionn√©e: ${image.width}x${image.height}');
      }

      // Encode as JPEG with quality reduction
      int quality = 85;
      Uint8List compressed = Uint8List.fromList(img.encodeJpg(image, quality: quality));
      
      // Further reduce quality if still too large (target: ~500KB)
      while (compressed.length > 500000 && quality > 20) {
        quality -= 15;
        compressed = Uint8List.fromList(img.encodeJpg(image, quality: quality));
        debugPrint('üîÑ Compression qualit√© $quality: ${compressed.length} bytes');
      }

      debugPrint('‚úÖ Image compress√©e: ${compressed.length} bytes (qualit√©: $quality)');
      return compressed;
    } catch (e) {
      debugPrint('‚ùå Erreur compression: $e, envoi original');
      return imageBytes;
    }
  }

  /// Get quick analysis prompts
  static List<QuickPrompt> getQuickPrompts() {
    return [
      QuickPrompt(
        icon: 'üîç',
        label: 'Analyse compl√®te',
        prompt: 'Effectuez une analyse compl√®te des m√©triques et identifiez toute anomalie potentielle.',
      ),
      QuickPrompt(
        icon: 'üëü',
        label: 'Semelles recommand√©es',
        prompt: 'Quelles semelles orthop√©diques recommandez-vous pour ce patient en fonction des mesures?',
      ),
      QuickPrompt(
        icon: 'üìè',
        label: 'V√©rifier pointure',
        prompt: 'La pointure indiqu√©e correspond-elle aux mesures relev√©es? Y a-t-il un √©cart significatif?',
      ),
      QuickPrompt(
        icon: '‚ö†Ô∏è',
        label: 'Anomalies',
        prompt: 'Identifiez les anomalies ou pathologies potentielles bas√©es sur les m√©triques disponibles.',
      ),
      QuickPrompt(
        icon: 'üìä',
        label: 'Rapport clinique',
        prompt: 'G√©n√©rez un rapport clinique synth√©tique pour ce patient incluant observations et recommandations.',
      ),
    ];
  }

  /// Clear conversation history (keep initial context)
  void clearHistory() {
    if (_history.length > 2) {
      final initial = _history.take(2).toList();
      _history.clear();
      _history.addAll(initial);
    }
  }

  /// Get full history for display
  List<AIMessage> getDisplayHistory() {
    final messages = <AIMessage>[];
    
    for (int i = 0; i < _history.length; i++) {
      final msg = _history[i];
      final isUser = msg['role'] == 'user';
      
      // Skip the initial context message (index 0)
      if (i == 0) continue;
      
      String text = '';
      bool hasImage = false;
      
      final content = msg['content'];
      if (content is String) {
        text = content;
      } else if (content is List) {
        for (final part in content) {
          if (part is Map && part['type'] == 'text') {
            text += part['text'] ?? '';
          } else if (part is Map && part['type'] == 'image') {
            hasImage = true;
          }
        }
      }
      
      if (text.isNotEmpty || hasImage) {
        messages.add(AIMessage(
          content: text,
          isUser: isUser,
          hasImage: hasImage,
          timestamp: DateTime.now(),
        ));
      }
    }
    
    return messages;
  }
}

/// Quick prompt suggestion
class QuickPrompt {
  final String icon;
  final String label;
  final String prompt;

  QuickPrompt({
    required this.icon,
    required this.label,
    required this.prompt,
  });
}

/// AI Message for display
class AIMessage {
  final String content;
  final bool isUser;
  final bool hasImage;
  final DateTime timestamp;

  AIMessage({
    required this.content,
    required this.isUser,
    this.hasImage = false,
    required this.timestamp,
  });
}
